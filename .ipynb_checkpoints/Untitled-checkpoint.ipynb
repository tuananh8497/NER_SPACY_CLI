{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reasonable-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, re\n",
    "from spacy.tokens import DocBin\n",
    "import skweak\n",
    "from skweak import heuristics, gazetteers, aggregation, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "restricted-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")   # We load an English-language model\n",
    "docs_copy = list(skweak.utils.docbin_reader(\"test_skweak.spacy\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "laughing-verification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TECHNICAL EDUCATION IN AUSTRALIA\\n\\nIntroduction\\n\\nThe general educationist who essays to write on the problems of technical education is apt to feel rather out of his depth.\\nLack of knowledge of technical processes and lack of first-hand contact with industry induce the feeling that he is approaching the subject from a distance and the fear that his views will be tinged with unreality.\\nHaving made this confession and having disavowed any intention of discussing technical education qu technical, on'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"small_version.txt\"\n",
    "texts = open(file_name).read() # your training data\n",
    "\n",
    "texts[0: 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "offshore-newman",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-cf1e3247b5fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#doc.cats = ... # set the true category labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "db = DocBin() # this will store the training examples\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp.make_doc(text)\n",
    "    #doc.cats = ... # set the true category labels\n",
    "    db.add(doc) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bizarre-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LF 2: detection of years with a regex\n",
    "lf2= heuristics.TokenConstraintAnnotator(\"years\", lambda tok: re.match(\"(19|20)\\d{2}$\", tok.text), \"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "minus-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LF 3: a gazetteer with a few names\n",
    "NAMES = [(\"New\", \"South\", \"Wales\"), (\"Tasmania\"), (\"Victoria\"), (\"Australia\", \"Capital\", \"Teritory\"), \n",
    "        (\"Northern\", \"Teritory\"), (\"Western\", \"Australia\")]\n",
    "#NAMES_2 = [(\"Australia\"), (\"England\"), (\"Singapore\")]\n",
    "trie = gazetteers.Trie(NAMES)\n",
    "lf1 = gazetteers.GazetteerAnnotator(\"states\", {\"STATES\":trie})\n",
    "\n",
    "#lf1 = gazeteers.GazetteerAnnotator(\"countries\", {\"COUNTRIES\":trie})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "scientific-penalty",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'spans'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-95cb1a8663b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocs_copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# apply the labelling functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlf1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlf2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# and aggregate them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skweak\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# We start by clearing all existing annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;31m# And we look at all suggested spans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'spans'"
     ]
    }
   ],
   "source": [
    "# We create a corpus (here with a single text)\n",
    "doc = docs_copy\n",
    "# apply the labelling functions\n",
    "doc = lf1(lf2(doc))\n",
    "\n",
    "# and aggregate them\n",
    "hmm = aggregation.HMM(\"hmm\", [\"DATE\", \"STATES\"])\n",
    "hmm.fit_and_aggregate([doc])\n",
    "\n",
    "# we can then visualise the final result (in Jupyter)\n",
    "utils.display_entities(doc, \"hmm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-bristol",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
